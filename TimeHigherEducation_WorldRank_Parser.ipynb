{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98ba5d10-fada-4274-af48-a13b539a78d3",
   "metadata": {},
   "source": [
    "**This is the TimeHigherEducation_WorldRank_Parser notebook**\n",
    "* Data Cleaning: Columns are cleaned and process to prepare for analysis. \n",
    "* Data Merging: An important step is gathering information on Longitude and Latitude for the streamlit map generation. \n",
    "* City names are found from the full address using City names from cities500.txt, a file from Geonames (http://download.geonames.org/export/dump/)\n",
    "* The longitude and latitude are added using the City and Country and geopy - computationally expensive ~13 minutes to run.\n",
    "* Data Visualization: The world rank data is visualized using streamlit using plotly express, scatter_geo. **refer to the streamlit app**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650e2ee8-012e-4b96-adcd-c0bf81b6ad92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15f614a-c57e-4684-8345-436b0ae157b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parsing the World Rank Data as df_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf98131-ee36-4f18-bba5-eaab4be15e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the dataframe\n",
    "df_rank = pd.read_csv(\"TimesHigherEducation_WorldRankings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea865f13-535c-4d27-ac41-a3a25c142fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the dataframe\n",
    "df_rank['intl_students'] = df_rank['intl_students'].replace('%', '', regex=True)\n",
    "df_rank['rank'] = df_rank['rank'].replace('\\–\\d*|\\+', '', regex=True)\n",
    "df_rank['overall_score'] = df_rank['overall_score'].replace('.*\\–', '', regex=True)\n",
    "df_rank['number_students'] = df_rank['number_students'].replace(',', '', regex=True)\n",
    "\n",
    "# Remove any rows without a university name and format the names\n",
    "df_rank = df_rank.dropna(subset=['name'])\n",
    "df_rank['name'] = df_rank['name'].replace('/world-university-rankings/', '', regex=True).str.strip()\n",
    "df_rank['name'] = df_rank['name'].replace('-', ' ', regex=True).str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6da29b2-048f-4058-981d-cfdba2cd228c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the GeoNames dataset of the city names: http://download.geonames.org/export/dump/\n",
    "# cities500.zip: conatins all cities with a population > 500 \n",
    "geo_df = pd.read_csv('cities500.txt', sep='\\t', header=None, names=['geonameid', 'name', 'asciiname', 'alternatenames', 'latitude', 'longitude', 'feature_class', 'feature_code', 'country_code', 'cc2', 'admin1_code', 'admin2_code', 'admin3_code', 'admin4_code', 'population', 'elevation', 'dem', 'timezone', 'modification_date'])\n",
    "\n",
    "# Extract these city names from the GeoNames dataset, when we are matching for the city, we do not want to match to these.\n",
    "city_names = geo_df['name'].tolist()\n",
    "city_names.remove('University')\n",
    "city_names.remove('Box')\n",
    "city_names.remove('Street')\n",
    "city_names.remove('College')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10ef004-447b-490a-90b4-f7fa1d08f299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, extract the country and city from the \"address\" column. The country is at the end of the address\n",
    "df_rank['Country'] = df_rank['address'].apply(lambda x: x.rsplit(',', 1)[-1].strip() if pd.notnull(x) else '') \n",
    "\n",
    "# The city is added if there is a match in the city_names list\n",
    "#df_rank['City'] = df_rank['address'].apply(lambda x: next((word for word in x.split(',') if word.strip() in city_names), None) if pd.notnull(x) else None)\n",
    "\n",
    "# Updated to find all of the matches of the address, then select only the first\n",
    "df_rank['City'] = df_rank['address'].apply(lambda x: [word.strip() for word in x.split(',') if word.strip() in city_names] if pd.notnull(x) else [])\n",
    "\n",
    "# Select the first entry in the 'City' column\n",
    "df_rank['City'] = df_rank['City'].apply(lambda x: x[0] if len(x) > 0 else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6839050-8c16-421c-8e14-00f6c4bf2e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now geopy geocoders is used to add longitude and latitude based on the city and country, this won't always be correct\n",
    "\n",
    "import time\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "city_list = df_rank['City'].tolist()\n",
    "country_list = df_rank['Country'].tolist()\n",
    "\n",
    "coordinates = [None]*len(city_list)\n",
    "geolocator = Nominatim(user_agent=\"mathesoa\") # Replace \"your_app_name\" with a custom user agent to avoid request throttling\n",
    "\n",
    "chunk_size = 50\n",
    "total_chunks = (len(city_list) + chunk_size - 1) // chunk_size\n",
    "\n",
    "for chunk in range(total_chunks):\n",
    "    start_index = chunk * chunk_size\n",
    "    end_index = min((chunk + 1) * chunk_size, len(city_list))\n",
    "\n",
    "    for i, (city, country) in enumerate(zip(city_list[start_index:end_index], country_list[start_index:end_index])):\n",
    "        if city is not None and country is not None:\n",
    "            try:\n",
    "                location = geolocator.geocode(f\"{city}, {country}\")\n",
    "                coordinates[start_index + i] = (location.latitude, location.longitude)\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    if chunk < total_chunks - 1:\n",
    "        print('first wait time')\n",
    "        time.sleep(10)  # Pause for 10 seconds between chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f94702b-4cef-4d9a-80ec-20541bca472b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the longitude and latitude columns in the dataframe\n",
    "df_rank['Latitude'] = [coord[0] if coord is not None else None for coord in coordinates]\n",
    "df_rank['Longitude'] = [coord[1] if coord is not None else None for coord in coordinates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0caed6-ed00-4224-9a1e-4e5ed99fa25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rank.to_csv('World_Rank_Plot.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf0f703-0cf4-400e-aacc-172b1533e0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rank.drop('all_city_matches', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ffd167-b66e-4152-9f36-29868042fec8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56527738-3a7b-4fec-ac26-e1f2553f5d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does not currently work, but in principle the address should be used to find the more accurate lon/lat values as well as the state\n",
    "\n",
    "from geopy.geocoders import Nominatim\n",
    "import time\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"mathesoa\")\n",
    "\n",
    "chunk_size = 50\n",
    "total_chunks = (len(df_rank) + chunk_size - 1) // chunk_size\n",
    "\n",
    "def get_state(address):\n",
    "    try:\n",
    "        location = geolocator.geocode(address)\n",
    "        state = location.raw['address']['state']\n",
    "        return state\n",
    "    except:\n",
    "        return ''\n",
    "\n",
    "df_rank['State'] = df_rank['address'].apply(get_state)\n",
    "\n",
    "for chunk in range(total_chunks):\n",
    "    start_index = chunk * chunk_size\n",
    "    end_index = min((chunk + 1) * chunk_size, len(df_rank))\n",
    "\n",
    "    # Get chunk of data\n",
    "    df_chunk = df_rank.loc[start_index:end_index].copy() # create a copy\n",
    "\n",
    "    # apply the function to each row in the chunk\n",
    "    df_chunk['State'] = df_chunk.apply(lambda row: get_state(row['address']), axis=1)\n",
    "\n",
    "    # Update dataframe with results\n",
    "    df_rank.loc[start_index:end_index] = df_chunk\n",
    "    \n",
    "    # Pause between chunks\n",
    "    if chunk < total_chunks - 1:\n",
    "        print('first wait time')\n",
    "        time.sleep(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
